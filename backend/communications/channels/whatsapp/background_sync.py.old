"""
WhatsApp Background Sync - Comprehensive sync functionality for WhatsApp channel
Implements paginated, non-blocking sync with progress tracking and resume capability
Part of the WhatsApp channel implementation following webhook-first architecture
"""
import logging
import asyncio
import requests
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple
from celery import shared_task
from django.contrib.auth import get_user_model
from django.utils import timezone as django_timezone
from django_tenants.utils import schema_context
from asgiref.sync import async_to_sync, sync_to_async

# Import from communications root since we're in channels/whatsapp
from communications.models import (
    Channel, UserChannelConnection, Conversation, SyncJob, SyncJobProgress, 
    SyncJobStatus, SyncJobType, Message, ChatAttendee, ConversationAttendee,
    MessageStatus, MessageDirection, AttendeeRole
)
from communications.unipile_sdk import unipile_service
from communications.utils.message_direction import determine_message_direction
from .utils.attendee_detection import WhatsAppAttendeeDetector
from .service import WhatsAppService

User = get_user_model()
logger = logging.getLogger(__name__)

# =========================================================================
# CONFIGURATION CONSTANTS
# =========================================================================

# Default batch sizes optimized for UniPile API rate limits and memory usage
SYNC_CONFIG = {
    'conversations_per_batch': 50,      # Conversations per API request
    'messages_per_batch': 100,          # Messages per API request
    'concurrent_chat_tasks': 3,         # Parallel chat processing tasks
    'max_retries': 5,                   # Maximum retry attempts
    'retry_delay_base': 60,             # Base retry delay in seconds
    'progress_update_interval': 10,     # Update progress every N items
}

# =========================================================================
# MAIN ORCHESTRATOR TASK
# =========================================================================

@shared_task(bind=True, max_retries=3)
def sync_account_comprehensive_background(
    self, 
    channel_id: str, 
    user_id: str, 
    sync_options: Optional[Dict[str, Any]] = None,
    tenant_schema: Optional[str] = None
):
    """
    Main orchestrator for comprehensive background sync
    Creates sync job and coordinates all sync phases with progress tracking
    
    Args:
        channel_id: Channel UUID to sync
        user_id: User UUID who initiated sync
        sync_options: Configuration options for sync
        tenant_schema: Tenant schema for multi-tenant support
    """
    sync_job = None
    
    try:
        # Apply sync options
        options = {**SYNC_CONFIG, **(sync_options or {})}
        
        logger.info(f"üöÄ Starting comprehensive background sync for channel {channel_id}")
        
        # Capture Celery task ID before async context
        task_id = self.request.id
        logger.info(f"üéØ Captured Celery task ID: {task_id}")
        
        if not task_id:
            logger.error(f"‚ùå No Celery task ID available - task not properly queued")
            raise ValueError("No Celery task ID available - task must be properly queued")
        
        # ASGI-compatible async execution - don't create new event loop
        # Use async_to_sync for proper ASGI compatibility
        from asgiref.sync import async_to_sync
        
        # Execute async function within ASGI context, passing task_id explicitly
        result = async_to_sync(_execute_comprehensive_sync_simple)(
            channel_id, user_id, options, tenant_schema, task_id
        )
        
        return result
            
    except Exception as e:
        logger.error(f"‚ùå Background sync failed for channel {channel_id}: {e}")
        
        # Update sync job status to failed
        if sync_job:
            try:
                if tenant_schema:
                    with schema_context(tenant_schema):
                        _mark_sync_job_failed(sync_job.id, str(e))
                else:
                    _mark_sync_job_failed(sync_job.id, str(e))
            except Exception as update_error:
                logger.error(f"Failed to update sync job status: {update_error}")
        
        # Retry with exponential backoff
        if self.request.retries < self.max_retries:
            retry_delay = options.get('retry_delay_base', 60) * (2 ** self.request.retries)
            raise self.retry(countdown=retry_delay)
        
        return {
            'success': False,
            'error': str(e),
            'channel_id': channel_id,
            'task_id': self.request.id
        }


# =========================================================================
# PAGINATED SYNC IMPLEMENTATION
# =========================================================================

async def _execute_comprehensive_sync_simple(
    channel_id: str, 
    user_id: str, 
    options: Dict[str, Any],
    tenant_schema: Optional[str] = None,
    task_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Execute comprehensive sync with pagination and progress tracking
    ASGI-compatible async implementation
    """
    from django_tenants.utils import schema_context
    
    async def _run_sync_without_context():
        # Get channel and user
        channel = await Channel.objects.aget(id=channel_id)
        user = await User.objects.aget(id=user_id)
        
        # Get the UserChannelConnection for direction detection
        connection = await UserChannelConnection.objects.filter(
            user=user,
            unipile_account_id=channel.unipile_account_id
        ).afirst()
        
        if connection:
            logger.info(f"‚úÖ Found user connection for direction detection")
        else:
            logger.warning(f"‚ö†Ô∏è No user connection found - direction detection will use fallback methods")
        
        # Create sync job
        sync_job = await SyncJob.objects.acreate(
            user=user,
            channel=channel,
            job_type=SyncJobType.COMPREHENSIVE,
            sync_options=options,
            celery_task_id=task_id,
            status=SyncJobStatus.RUNNING,
            started_at=django_timezone.now()
        )
        
        logger.info(f"üìä Created sync job {sync_job.id} for comprehensive sync")
        
        try:
            # Phase 1: Get conversation count estimate
            await _update_sync_progress(sync_job, 'initializing', 'Getting conversation estimate')
            
            total_conversations = await _estimate_conversation_count(channel, options)
            await sync_job.aupdate_progress(
                conversations_total=total_conversations,
                conversations_processed=0,
                messages_processed=0,
                current_phase='fetching_conversations'
            )
            
            # Phase 2 & 3: Use WhatsApp service for actual sync
            await _update_sync_progress(sync_job, 'running_sync', 'Starting WhatsApp sync')
            
            from .service import WhatsAppService
            whatsapp_service = WhatsAppService(channel=channel)
            
            # Initialize counters
            total_messages_synced = 0
            
            # Sync conversations
            conversations_result = await whatsapp_service.sync_conversations(
                channel=channel,
                days_back=options.get('days_back', 30),
                limit=50  # Sync up to 50 conversations
            )
            
            conversations_synced = conversations_result.get('synced_count', 0)
            conversations_list = conversations_result.get('conversations', [])
            
            logger.info(f"‚úÖ Synced {conversations_synced} conversations")
            
            # Update progress
            await sync_job.aupdate_progress(
                conversations_processed=conversations_synced,
                conversations_total=conversations_synced,
                current_phase='fetching_messages'
            )
            
            # Sync messages for each conversation
            if conversations_list:
                max_messages_per_chat = options.get('max_messages_per_chat', 100)
                
                for idx, conversation in enumerate(conversations_list):
                    try:
                        external_id = conversation.external_thread_id
                        if not external_id:
                            continue
                        
                        # Sync messages - call with correct parameters
                        messages_result = await whatsapp_service.sync_messages(
                            user=user,
                            account_id=channel.unipile_account_id,
                            conversation_id=external_id,
                            force_sync=True
                        )
                        
                        # Get count from messages array since sync_messages returns 'messages' not 'synced_count'
                        messages_count = len(messages_result.get('messages', []))
                        total_messages_synced += messages_count
                        
                        logger.info(f"   ‚úÖ Synced {messages_count} messages for conversation {external_id[:8]}")
                        
                        # Update progress
                        await sync_job.aupdate_progress(
                            messages_processed=total_messages_synced,
                            current_step=f'conversation_{idx+1}_of_{len(conversations_list)}'
                        )
                        
                    except Exception as msg_error:
                        logger.error(f"Failed to sync messages: {msg_error}")
                        continue
            
            messages_synced = total_messages_synced
            
            sync_result = {
                'chats_synced': conversations_synced,
                'messages_synced': messages_synced
            }
            
            await sync_job.aupdate_progress(
                conversations_processed=conversations_synced,
                conversations_total=conversations_synced,  # Update total based on actual results
                messages_processed=messages_synced,
                current_phase='completed',
                current_step='sync_finished'
            )
            
            # Phase 4: Finalization
            conversations_data = [{'conversation_id': f'sync_{i}'} for i in range(conversations_synced)]
            await _finalize_sync_job(sync_job, conversations_data, messages_synced)
            
            result = {
                'success': True,
                'sync_job_id': str(sync_job.id),
                'conversations_synced': conversations_synced,
                'messages_synced': messages_synced,
                'channel_id': channel_id,
                'task_id': task_id
            }
            
            logger.info(f"‚úÖ Comprehensive sync completed: {result}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Sync execution failed: {e}")
            await _mark_sync_job_failed_async(sync_job, str(e))
            raise
    
    # Execute with tenant context
    if not tenant_schema:
        raise ValueError("No tenant schema provided for background sync task")
    
    # Use the working comprehensive sync service
    from django_tenants.utils import schema_context
    
    async def _run_sync():
        # Import the sync function 
        from asgiref.sync import sync_to_async
        from django_tenants.utils import schema_context
        
        # Execute the entire sync in a synchronous context with proper tenant schema
        @sync_to_async
        def run_sync_with_tenant_context():
            with schema_context(tenant_schema):
                from asgiref.sync import async_to_sync
                
                # Get channel and user (sync)
                channel = Channel.objects.get(id=channel_id)
                user = User.objects.get(id=user_id)
                
                # Get the UserChannelConnection for direction detection
                connection = UserChannelConnection.objects.filter(
                    user=user,
                    unipile_account_id=channel.unipile_account_id
                ).first()
                
                # Create sync job
                sync_job = SyncJob.objects.create(
                    user=user,
                    channel=channel,
                    job_type=SyncJobType.COMPREHENSIVE,
                    sync_options=options,
                    celery_task_id=task_id,
                    status=SyncJobStatus.RUNNING,
                    started_at=django_timezone.now()
                )
                
                # Use WhatsApp service with proper async context
                from .service import WhatsAppService
                
                # Initialize WhatsApp service with channel (it will get account identifier automatically)
                whatsapp_service = WhatsAppService(channel=channel)
                
                if whatsapp_service.account_identifier:
                    logger.info(f"üìû Using account identifier for owner detection: {whatsapp_service.account_identifier}")
                else:
                    logger.warning("‚ö†Ô∏è No account identifier found - direction detection may not work properly")
                
                # Perform sync using WhatsApp service
                logger.info(f"üì± Starting sync for channel {channel.id}")
                
                # Initialize counters
                conversations_synced = 0
                messages_synced = 0
                total_messages_synced = 0
                
                try:
                    # Phase 1: Update initial progress
                    sync_job.update_progress(
                        current_phase='fetching_conversations',
                        conversations_total=0,
                        conversations_processed=0,
                        messages_processed=0
                    )
                    
                    # Phase 2: Sync conversations directly from UniPile API
                    logger.info(f"üì± Fetching conversations from UniPile API...")
                    
                    # Use async_to_sync to call the async method
                    from asgiref.sync import async_to_sync
                    from communications.models import Conversation
                    
                    # Get days_back from options
                    days_back = options.get('days_back', 30)
                    
                    # Fetch conversations directly from UniPile API
                    api_result = async_to_sync(whatsapp_service.client.get_conversations)(
                        channel.unipile_account_id
                    )
                    
                    if not api_result.get('success'):
                        logger.error(f"Failed to fetch conversations from API: {api_result.get('error')}")
                        raise Exception(f"API Error: {api_result.get('error')}")
                    
                    api_conversations = api_result.get('conversations', [])
                    logger.info(f"üìä Fetched {len(api_conversations)} conversations from UniPile")
                    
                    # Store each conversation in the database
                    conversations_list = []
                    logger.info(f"üîç Channel being used: {channel.id} - {channel.unipile_account_id}")
                    for conv_data in api_conversations:
                        chat_id = conv_data.get('id') or conv_data.get('chat_id')
                        if not chat_id:
                            logger.warning(f"‚ö†Ô∏è Skipping conversation with no ID: {conv_data}")
                            continue
                        
                        logger.info(f"üîç Processing conversation with chat_id: {chat_id}")
                            
                        # First, fetch attendees for this chat
                        attendees_result = async_to_sync(whatsapp_service.client.get_attendees)(
                            account_id=channel.unipile_account_id,
                            chat_id=chat_id
                        )
                        
                        # Add attendees data to conv_data for storage
                        if attendees_result.get('success'):
                            conv_data['attendees'] = attendees_result.get('attendees', [])
                            logger.info(f"üì• Fetched {len(conv_data['attendees'])} attendees for chat {chat_id[:8]}...")
                        
                        # Store conversation directly (sync version)
                        # Extract conversation name from data
                        chat_name = conv_data.get('name') or f'WhatsApp Chat {chat_id[:8]}'
                        
                        # Create or update conversation directly
                        conversation, created = Conversation.objects.update_or_create(
                            channel=channel,
                            external_thread_id=chat_id,
                            defaults={
                                'subject': chat_name,
                                'status': 'active',
                                'last_message_at': django_timezone.now(),
                                'conversation_type': 'group' if len(conv_data.get('attendees', [])) > 2 else 'direct',
                                'participant_count': len(conv_data.get('attendees', [])),
                                'metadata': {
                                    'api_data': conv_data,
                                    'synced_from': 'background_sync',
                                    'sync_time': django_timezone.now().isoformat()
                                }
                            }
                        )
                        if conversation:
                            conversations_list.append(conversation)
                            logger.info(f"‚úÖ Found stored conversation: {chat_id[:8]}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Could not find stored conversation: {chat_id[:8]}")
                    
                    conversations_synced = len(conversations_list)
                    
                    logger.info(f"‚úÖ Synced {conversations_synced} conversations")
                    logger.info(f"üìã Conversations list has {len(conversations_list)} items")
                    
                    # Update progress after conversations
                    sync_job.update_progress(
                        current_phase='fetching_messages',
                        conversations_total=conversations_synced,
                        conversations_processed=conversations_synced,
                        messages_processed=0
                    )
                    
                    # Phase 3: Sync messages for each conversation
                    if conversations_list:
                        logger.info(f"üì® Starting to sync messages for {len(conversations_list)} conversations")
                        
                        max_messages_per_chat = options.get('max_messages_per_chat', 100)
                        
                        for idx, conversation in enumerate(conversations_list):
                            try:
                                # Get the conversation's external ID
                                external_id = conversation.external_thread_id
                                if not external_id:
                                    continue
                                
                                logger.info(f"üì® Syncing messages for conversation {idx+1}/{len(conversations_list)}: {external_id[:8]}...")
                                
                                # Fetch messages directly from UniPile API
                                # NOTE: Don't pass account_id - causes 400 errors with UniPile API
                                api_messages_result = async_to_sync(whatsapp_service.client.get_messages)(
                                    account_id=None,  # Must be None to avoid 400 errors
                                    conversation_id=external_id,
                                    limit=max_messages_per_chat
                                )
                                
                                if not api_messages_result.get('success'):
                                    logger.warning(f"Failed to fetch messages for conversation {external_id}: {api_messages_result.get('error')}")
                                    continue
                                
                                api_messages = api_messages_result.get('messages', [])
                                
                                # Store messages in database
                                if api_messages:
                                    async_to_sync(whatsapp_service._store_messages)(
                                        channel=channel,
                                        conversation=conversation,
                                        messages=api_messages,
                                        conversation_id=external_id
                                    )
                                
                                messages_count = len(api_messages)
                                total_messages_synced += messages_count
                                
                                # Update progress after each conversation
                                sync_job.update_progress(
                                    messages_processed=total_messages_synced,
                                    current_step=f'conversation_{idx+1}_of_{len(conversations_list)}'
                                )
                                
                                logger.info(f"   ‚úÖ Synced {messages_count} messages for conversation {external_id[:8]}")
                                
                            except Exception as msg_error:
                                logger.error(f"   ‚ùå Failed to sync messages for conversation: {msg_error}")
                                continue
                    
                    messages_synced = total_messages_synced
                    logger.info(f"‚úÖ Total sync completed: {conversations_synced} chats, {messages_synced} messages")
                    
                except Exception as sync_error:
                    logger.error(f"‚ùå Sync failed: {sync_error}", exc_info=True)
                    # Keep partial results if any
                
                sync_result = {
                    'chats_synced': conversations_synced,
                    'messages_synced': messages_synced
                }
                
                # Update sync job with results
                conversations_synced = sync_result.get('chats_synced', 0)
                messages_synced = sync_result.get('messages_synced', 0)
                
                # Finalize sync job
                sync_job.status = SyncJobStatus.COMPLETED
                sync_job.completed_at = django_timezone.now()
                sync_job.result_summary = {
                    'conversations_synced': conversations_synced,
                    'messages_synced': messages_synced,
                    'completed_at': django_timezone.now().isoformat(),
                    'duration_seconds': (
                        sync_job.completed_at - sync_job.started_at
                    ).total_seconds() if sync_job.started_at else 0
                }
                sync_job.save(update_fields=['status', 'completed_at', 'result_summary'])
                
                return {
                    'success': True,
                    'sync_job_id': str(sync_job.id),
                    'conversations_synced': conversations_synced,
                    'messages_synced': messages_synced,
                    'channel_id': channel_id,
                    'task_id': task_id
                }
        
        return await run_sync_with_tenant_context()
    
    return await _run_sync()


# =========================================================================
# HELPER FUNCTIONS FOR PAGINATED SYNC (UNUSED IN CURRENT IMPLEMENTATION) 
# =========================================================================


async def _sync_conversations_paginated(
    sync_job: SyncJob,
    channel: Channel,
    options: Dict[str, Any],
    connection: Optional[UserChannelConnection] = None
) -> List[Dict[str, Any]]:
    """
    Sync conversations with pagination and progress updates
    """
    logger.info(f"üì± Starting paginated conversation sync for {channel.name}")
    
    # Initialize attendee detector with channel (it will get account identifier automatically)
    attendee_detector = WhatsAppAttendeeDetector(channel=channel)
    
    client = unipile_service.get_client()
    batch_size = options['conversations_per_batch']
    cursor = sync_job.pagination_state.get('conversations_cursor')
    
    all_conversations = []
    batch_number = 0
    
    # Map channel type to UniPile account type
    account_type_map = {
        'whatsapp': 'WHATSAPP',
        'linkedin': 'LINKEDIN',
        'gmail': 'GOOGLE',
        'outlook': 'OUTLOOK'
    }
    account_type = account_type_map.get(channel.channel_type, channel.channel_type.upper())
    
    while True:
        batch_number += 1
        
        # Create progress entry for this batch
        progress_entry = await SyncJobProgress.objects.acreate(
            sync_job=sync_job,
            phase_name='fetching_conversations',
            step_name=f'batch_{batch_number}',
            items_total=batch_size
        )
        
        try:
            # Get batch of conversations
            response = await client.messaging.get_chats_batch(
                account_id=channel.unipile_account_id,
                account_type=account_type,
                cursor=cursor,
                limit=batch_size
            )
            
            conversations = response.get('items', [])
            if not conversations:
                logger.info("üì± No more conversations to sync")
                break
            
            # Process this batch of conversations with detailed tracking
            batch_processed = []
            batch_errors = []
            start_time = datetime.now(timezone.utc)
            
            for i, conv_data in enumerate(conversations):
                conv_start_time = datetime.now(timezone.utc)
                try:
                    # Get attendees for this conversation
                    chat_id = conv_data.get('id')
                    conv_name = conv_data.get('name', 'Unnamed Conversation')
                    
                    if chat_id:
                        attendees = await _get_chat_attendees(client, chat_id)
                        
                        # Process attendees using WhatsApp detector
                        attendees_list = []
                        for att_data in attendees:
                            # Create or update attendee
                            attendee = await sync_to_async(attendee_detector.create_or_update_attendee)(
                                att_data,
                                conversation=None,  # Will link to conversation later
                                channel=channel
                            )
                            attendees_list.append(attendee)
                        
                        # Process conversation
                        chat_name = conv_data.get('name') or f'WhatsApp Chat {chat_id[:8]}'
                        
                        # Create or update conversation
                        conversation, created = await sync_to_async(Conversation.objects.update_or_create)(
                            channel=channel,
                            external_thread_id=chat_id,
                            defaults={
                                'subject': chat_name,
                                'status': 'active',
                                'last_message_at': django_timezone.now(),
                                'conversation_type': 'group' if len(attendees_list) > 2 else 'direct',
                                'participant_count': len(attendees_list),
                                'metadata': {
                                    'api_data': conv_data,
                                    'synced_from': 'background_sync',
                                    'sync_time': django_timezone.now().isoformat()
                                }
                            }
                        )
                        
                        # Link attendees to conversation
                        if attendees_list:
                            for attendee in attendees_list:
                                await sync_to_async(ConversationAttendee.objects.get_or_create)(
                                    conversation=conversation,
                                    attendee=attendee,
                                    defaults={
                                        'role': AttendeeRole.MEMBER,
                                        'is_active': True
                                    }
                                )
                        
                        # Calculate processing time
                        conv_processing_time = int((datetime.now(timezone.utc) - conv_start_time).total_seconds() * 1000)
                        
                        batch_processed.append({
                            'conversation_id': str(conversation.id),
                            'external_id': chat_id,
                            'name': conv_name,
                            'created': created,
                            'processing_time_ms': conv_processing_time,
                            'attendee_count': len(attendees_list)
                        })
                        
                        # Send detailed progress update every 5 conversations
                        if (i + 1) % 5 == 0:
                            progress_current = len(all_conversations) + len(batch_processed)
                            await sync_job.aupdate_progress(
                                conversations_processed=progress_current,
                                current_phase='processing_conversations',
                                current_step=f'batch_{batch_number}_item_{i+1}',
                                current_conversation_name=conv_name,
                                batch_progress_percent=int((i + 1) / len(conversations) * 100),
                                avg_processing_time_ms=conv_processing_time
                            )
                        
                except Exception as conv_error:
                    error_msg = str(conv_error)
                    batch_errors.append({
                        'conversation_id': conv_data.get('id', 'unknown'),
                        'conversation_name': conv_data.get('name', 'Unnamed'),
                        'error': error_msg
                    })
                    logger.error(f"Failed to process conversation {conv_data.get('id', 'unknown')}: {conv_error}")
                    continue
            
            all_conversations.extend(batch_processed)
            
            # Calculate batch performance metrics
            batch_processing_time = int((datetime.now(timezone.utc) - start_time).total_seconds() * 1000)
            avg_conversation_time = batch_processing_time / len(batch_processed) if batch_processed else 0
            error_rate = len(batch_errors) / len(conversations) * 100 if conversations else 0
            
            # Update progress with detailed information
            await progress_entry.mark_completed(len(batch_processed))
            await sync_job.aupdate_progress(
                conversations_processed=len(all_conversations),
                current_phase='fetching_conversations',
                current_step=f'batch_{batch_number}_completed',
                batch_number=batch_number,
                conversations_in_batch=len(batch_processed),
                batch_errors_count=len(batch_errors),
                batch_error_rate_percent=error_rate,
                batch_processing_time_ms=batch_processing_time,
                avg_conversation_processing_ms=int(avg_conversation_time),
                api_response_time_ms=response.get('batch_info', {}).get('request_time_ms', 0),
                recent_errors=batch_errors[-3:] if batch_errors else [],  # Last 3 errors
                processing_rate_per_minute=int(len(batch_processed) * 60000 / batch_processing_time) if batch_processing_time > 0 else 0
            )
            
            logger.info(f"üìä Batch {batch_number} completed: {len(batch_processed)} conversations processed, {len(batch_errors)} errors, {int(avg_conversation_time)}ms avg time")
            
            # Send intermediate progress updates with performance data
            if len(all_conversations) % 10 == 0:  # Every 10 conversations
                estimated_remaining = sync_job.progress.get('conversations_total', 0) - len(all_conversations)
                estimated_time_remaining_minutes = int(estimated_remaining * avg_conversation_time / 60000) if avg_conversation_time > 0 else 0
                
                await sync_job.aupdate_progress(
                    conversations_processed=len(all_conversations),
                    estimated_time_remaining_minutes=estimated_time_remaining_minutes,
                    current_processing_rate_per_minute=int(len(all_conversations) * 60000 / batch_processing_time) if batch_processing_time > 0 else 0,
                    current_phase='fetching_conversations',
                    current_step=f'processing_conversation_{len(all_conversations)}',
                    latest_conversation=batch_processed[-1]['conversation_id'] if batch_processed else None
                )
            
            # Check for next page
            cursor = response.get('next_cursor')
            has_more = response.get('has_more', False)
            
            # Save pagination state for resume capability
            sync_job.pagination_state['conversations_cursor'] = cursor
            await sync_job.asave(update_fields=['pagination_state'])
            
            if not has_more or not cursor:
                break
                
            logger.info(f"üì± Completed conversation batch {batch_number}: {len(batch_processed)} processed")
            
        except Exception as batch_error:
            logger.error(f"Conversation batch {batch_number} failed: {batch_error}")
            await progress_entry.mark_failed(str(batch_error))
            
            # Continue with next batch instead of failing entire sync
            cursor = response.get('next_cursor') if 'response' in locals() else None
            if not cursor:
                break
    
    logger.info(f"‚úÖ Conversation sync completed: {len(all_conversations)} conversations processed")
    return all_conversations


async def _sync_messages_paginated(
    sync_job: SyncJob,
    channel: Channel,
    conversations: List[Dict[str, Any]],
    options: Dict[str, Any],
    connection: Optional[UserChannelConnection] = None
) -> int:
    """
    Sync messages for all conversations with pagination
    """
    logger.info(f"üì® Starting paginated message sync for {len(conversations)} conversations")
    
    client = unipile_service.get_client()
    batch_size = options['messages_per_batch']
    total_messages_synced = 0
    
    for i, conv_data in enumerate(conversations):
        external_id = conv_data.get('external_id')
        if not external_id:
            continue
            
        # Create progress entry for this conversation's messages
        progress_entry = await SyncJobProgress.objects.acreate(
            sync_job=sync_job,
            phase_name='processing_messages',
            step_name=f'conversation_{external_id[:8]}',
            items_total=0  # Will update as we discover message count
        )
        
        try:
            # Get pagination state for this conversation
            conv_cursor = sync_job.pagination_state.get(f'messages_cursor_{external_id}')
            conv_messages_synced = 0
            
            while True:
                # Get batch of messages for this conversation
                response = await client.messaging.get_messages_batch(
                    chat_id=external_id,
                    cursor=conv_cursor,
                    limit=batch_size
                )
                
                messages = response.get('items', [])
                if not messages:
                    break
                
                # Process messages with proper attendee detection and direction
                batch_processed = 0
                attendee_detector = WhatsAppAttendeeDetector(channel=channel)
                whatsapp_service = WhatsAppService(channel=channel)
                # Get account_identifier for direction detection
                account_identifier = attendee_detector.account_identifier
                
                for message_data in messages:
                    try:
                        # Get the conversation object
                        conversation = await Conversation.objects.aget(
                            channel=channel,
                            external_thread_id=external_id
                        )
                        
                        # Extract message details
                        msg_id = message_data.get('id')
                        msg_text = message_data.get('text', '')
                        msg_timestamp = message_data.get('timestamp')
                        
                        # Detect and create/update attendees
                        sender_info = message_data.get('sender', {})
                        if sender_info:
                            attendee = await sync_to_async(attendee_detector.create_or_update_attendee)(
                                sender_info,
                                conversation=conversation,
                                channel=channel
                            )
                        else:
                            attendee = None
                        
                        # Determine message direction
                        from communications.utils.message_direction import determine_message_direction
                        business_account_id = connection.connection_config.get('phone_number') if connection else None
                        direction_str = determine_message_direction(
                            message_data,
                            'whatsapp',
                            business_account_id
                        )
                        # Convert 'in'/'out' to model's expected 'inbound'/'outbound'
                        direction = 'inbound' if direction_str == 'in' else 'outbound'
                        
                        # Create or update message
                        message, created = await Message.objects.aupdate_or_create(
                            channel=channel,
                            external_message_id=msg_id,
                            defaults={
                                'conversation': conversation,
                                'content': msg_text,
                                'sender': attendee,  # Use the sender field
                                'direction': direction,
                                'status': 'delivered',
                                'created_at': msg_timestamp or django_timezone.now(),
                                'metadata': {
                                    'api_data': message_data,
                                    'synced_from': 'background_sync',
                                    'sync_time': django_timezone.now().isoformat()
                                }
                            }
                        )
                        
                        if created:
                            batch_processed += 1
                            
                    except Exception as msg_error:
                        logger.error(f"Failed to process message {message_data.get('id', 'unknown')}: {msg_error}")
                        continue
                
                conv_messages_synced += batch_processed
                total_messages_synced += batch_processed
                
                # Update progress
                progress_entry.items_total = conv_messages_synced
                await progress_entry.mark_completed(conv_messages_synced)
                
                # Check for next page
                conv_cursor = response.get('next_cursor')
                has_more = response.get('has_more', False)
                
                # Save cursor state
                sync_job.pagination_state[f'messages_cursor_{external_id}'] = conv_cursor
                await sync_job.asave(update_fields=['pagination_state'])
                
                if not has_more or not conv_cursor:
                    break
            
            # Update overall progress
            await sync_job.aupdate_progress(
                messages_processed=total_messages_synced,
                current_step=f'conversation_{i+1}_of_{len(conversations)}_completed'
            )
            
            logger.info(f"üì® Conversation {external_id[:8]}: {conv_messages_synced} messages synced")
            
        except Exception as conv_error:
            logger.error(f"Message sync failed for conversation {external_id}: {conv_error}")
            await progress_entry.mark_failed(str(conv_error))
            continue
    
    logger.info(f"‚úÖ Message sync completed: {total_messages_synced} messages processed")
    return total_messages_synced


# =========================================================================
# HELPER FUNCTIONS
# =========================================================================

async def _estimate_conversation_count(channel: Channel, options: Dict[str, Any]) -> int:
    """
    Get rough estimate of conversation count for progress tracking
    """
    try:
        client = unipile_service.get_client()
        
        # Get first page to estimate total
        response = await client.messaging.get_chats_batch(
            account_id=channel.unipile_account_id,
            limit=10  # Small batch for estimation
        )
        
        items = response.get('items', [])
        if len(items) < 10:
            # If we got fewer than requested, this is probably the total
            return len(items)
        else:
            # Estimate based on typical account size
            # This is rough estimation - actual count determined during sync
            return min(1000, len(items) * 20)  # Cap at reasonable number
            
    except Exception as e:
        logger.warning(f"Failed to estimate conversation count: {e}")
        return 100  # Default estimate


async def _get_chat_attendees(client, chat_id: str) -> List[Dict[str, Any]]:
    """Get attendees for a specific chat"""
    try:
        response = await client._make_request('GET', f'chats/{chat_id}/attendees')
        return response.get('items', []) if response else []
    except Exception as e:
        logger.error(f"Failed to get attendees for chat {chat_id}: {e}")
        return []


async def _update_sync_progress(
    sync_job: SyncJob, 
    phase: str, 
    step: str, 
    **kwargs
):
    """Update sync job progress"""
    await sync_job.aupdate_progress(
        current_phase=phase,
        current_step=step,
        **kwargs
    )


async def _finalize_sync_job(
    sync_job: SyncJob, 
    conversations: List[Dict[str, Any]], 
    messages_count: int
):
    """Mark sync job as completed"""
    sync_job.status = SyncJobStatus.COMPLETED
    sync_job.completed_at = django_timezone.now()
    sync_job.result_summary = {
        'conversations_synced': len(conversations),
        'messages_synced': messages_count,
        'completed_at': django_timezone.now().isoformat(),
        'duration_seconds': (
            sync_job.completed_at - sync_job.started_at
        ).total_seconds() if sync_job.started_at else 0
    }
    
    await sync_job.asave(update_fields=[
        'status', 'completed_at', 'result_summary'
    ])
    
    logger.info(f"üéâ Sync job {sync_job.id} completed successfully")


async def _mark_sync_job_failed_async(sync_job: SyncJob, error_message: str):
    """Mark sync job as failed (async version)"""
    sync_job.status = SyncJobStatus.FAILED
    sync_job.completed_at = django_timezone.now()
    sync_job.error_details = {
        'error': error_message,
        'failed_at': django_timezone.now().isoformat()
    }
    sync_job.error_count += 1
    
    await sync_job.asave(update_fields=[
        'status', 'completed_at', 'error_details', 'error_count'
    ])


def _mark_sync_job_failed(sync_job_id: str, error_message: str):
    """Mark sync job as failed (sync version for error handling)"""
    try:
        sync_job = SyncJob.objects.get(id=sync_job_id)
        sync_job.status = SyncJobStatus.FAILED
        sync_job.completed_at = django_timezone.now()
        sync_job.error_details = {
            'error': error_message,
            'failed_at': django_timezone.now().isoformat()
        }
        sync_job.error_count += 1
        sync_job.save(update_fields=[
            'status', 'completed_at', 'error_details', 'error_count'
        ])
    except Exception as e:
        logger.error(f"Failed to update sync job {sync_job_id} status: {e}")


# =========================================================================
# ASGI-COMPATIBLE SYNC HELPER FUNCTIONS
# =========================================================================

def _estimate_conversation_count_sync(channel: Channel, options: Dict[str, Any]) -> int:
    """
    Get rough estimate of conversation count for progress tracking
    ASGI-compatible sync version
    """
    try:
        client = unipile_service.get_client()
        
        # Map channel type to UniPile account type
        account_type_map = {
            'whatsapp': 'WHATSAPP',
            'linkedin': 'LINKEDIN', 
            'gmail': 'GOOGLE',
            'outlook': 'OUTLOOK'
        }
        account_type = account_type_map.get(channel.channel_type, channel.channel_type.upper())
        
        # Get first page to estimate total (using sync version for now)
        # Note: This would need to be adapted to actual UniPile client API structure
        response = {
            'items': [],  # Placeholder - would come from actual UniPile API call
            'has_more': False,
            'estimated_total': 50  # Placeholder estimate
        }
        
        estimated_total = response.get('estimated_total', 50)
        logger.info(f"üìä Estimated conversation count: {estimated_total}")
        
        return estimated_total
        
    except Exception as e:
        logger.warning(f"Failed to estimate conversation count: {e}")
        return 100  # Default estimate


def _run_comprehensive_sync_simplified(channel: Channel, options: Dict[str, Any], connection: Optional[UserChannelConnection] = None, sync_job: Optional[SyncJob] = None) -> Dict[str, Any]:
    """
    Simplified comprehensive sync using sync methods and same approach as ComprehensiveSyncService
    """
    stats = {
        'attendees_synced': 0,
        'chats_synced': 0,
        'messages_synced': 0,
        'conversations_created': 0,
        'conversations_updated': 0,
        'errors': []
    }
    
    try:
        logger.info(f"üîÑ Starting simplified comprehensive sync for {channel.name}")
        
        # Initialize attendee detector with channel (it will get account identifier automatically)
        attendee_detector = WhatsAppAttendeeDetector(channel=channel)
        
        # Get UniPile client
        client = unipile_service.get_client()
        
        # Map channel type to account type (same as comprehensive sync service)
        account_type_map = {
            'whatsapp': 'WHATSAPP',
            'linkedin': 'LINKEDIN', 
            'gmail': 'GOOGLE',
            'outlook': 'OUTLOOK'
        }
        account_type = account_type_map.get(channel.channel_type, channel.channel_type.upper())
        
        # Step 1: Get all chats (using direct HTTP requests for sync)
        logger.info(f"üì± Getting all chats for {channel.name}")
        
        # Use requests library for sync HTTP calls 
        import requests
        
        url = f"{client.base_url}/chats"
        headers = {
            'X-API-KEY': client.access_token,
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        params = {
            'account_id': channel.unipile_account_id,
            'account_type': account_type,
            'limit': 10  # Start with small number
        }
        
        chats_response = requests.get(url, headers=headers, params=params).json()
        
        chats = chats_response.get('items', []) if chats_response else []
        logger.info(f"üì± Found {len(chats)} chats to process")
        
        # Update progress with chat count
        if sync_job:
            sync_job.progress.update({
                'conversations_total': len(chats),
                'conversations_processed': 0,
                'current_phase': 'processing_conversations',
                'current_step': f'Found {len(chats)} conversations to sync'
            })
            sync_job.save(update_fields=['progress'])
        
        # Step 2: Process each chat
        for i, chat_data in enumerate(chats, 1):
            try:
                chat_id = chat_data.get('id')
                if not chat_id:
                    continue
                
                chat_name = chat_data.get('name', f'Chat {i}')
                logger.info(f"üîÑ Processing chat {i}/{len(chats)}: {chat_name}")
                
                # Update progress
                if sync_job:
                    sync_job.progress.update({
                        'conversations_processed': i-1,
                        'current_step': f'Processing chat: {chat_name}',
                        'current_conversation_name': chat_name
                    })
                    sync_job.save(update_fields=['progress'])
                
                # Get attendees for this chat (sync version)
                attendees_url = f"{client.base_url}/chats/{chat_id}/attendees"
                attendees_response = requests.get(attendees_url, headers=headers).json()
                attendees = attendees_response.get('items', []) if attendees_response else []
                
                # Process attendees using WhatsApp detector (sync version)
                attendees_list = []
                for att_data in attendees:
                    # Create or update attendee
                    attendee = attendee_detector.create_or_update_attendee(
                        att_data,
                        conversation=None,  # Will link to conversation later
                        channel=channel
                    )
                    attendees_list.append(attendee)
                
                stats['attendees_synced'] += len(attendees_list)
                
                # Process conversation
                chat_name = chat_data.get('name') or f'WhatsApp Chat {chat_id[:8]}'
                
                # Create or update conversation
                conversation, created = Conversation.objects.update_or_create(
                    channel=channel,
                    external_thread_id=chat_id,
                    defaults={
                        'subject': chat_name,
                        'status': 'active',
                        'last_message_at': django_timezone.now(),
                        'conversation_type': 'group' if len(attendees_list) > 2 else 'direct',
                        'participant_count': len(attendees_list),
                        'metadata': {
                            'api_data': chat_data,
                            'synced_from': 'background_sync_simple',
                            'sync_time': django_timezone.now().isoformat()
                        }
                    }
                )
                
                # Link attendees to conversation
                if attendees_list:
                    for attendee in attendees_list:
                        ConversationAttendee.objects.get_or_create(
                            conversation=conversation,
                            attendee=attendee,
                            defaults={
                                'role': AttendeeRole.MEMBER,
                                'is_active': True
                            }
                        )
                
                if created:
                    stats['conversations_created'] += 1
                else:
                    stats['conversations_updated'] += 1
                    
                stats['chats_synced'] += 1
                
                # Get messages for this chat
                messages_url = f"{client.base_url}/chats/{chat_id}/messages"
                messages_params = {'limit': options.get('max_messages_per_chat', 100)}
                messages_response = requests.get(messages_url, headers=headers, params=messages_params).json()
                messages = messages_response.get('items', []) if messages_response else []
                
                # Process messages
                messages_created = 0
                for message_data in messages:
                    try:
                        if not message_data or not isinstance(message_data, dict) or not message_data.get('id'):
                            continue
                        
                        # Use attendee detector to extract sender info and create/update attendee
                        # The detector handles all the field extraction logic including sender_attendee_id, sender_id, etc.
                        sender_info = attendee_detector.extract_attendee_from_webhook(message_data)
                        
                        # Create or update the attendee based on extracted info
                        sender_attendee = None
                        if sender_info.get('external_id'):
                            sender_attendee = attendee_detector.create_or_update_attendee(
                                sender_info,
                                conversation=conversation,
                                channel=channel
                            )
                        
                        # Determine message direction using centralized detection
                        direction_str = determine_message_direction(
                            message_data,
                            'whatsapp',
                            channel=channel  # Use channel object for centralized detection
                        )
                        # Convert 'in'/'out' to model's expected 'inbound'/'outbound'
                        direction = 'inbound' if direction_str == 'in' else 'outbound'
                        
                        # Create or update message
                        message, created = Message.objects.update_or_create(
                            channel=channel,
                            external_message_id=message_data.get('id'),
                            defaults={
                                'conversation': conversation,
                                'sender': sender_attendee,
                                'content': message_data.get('text', ''),
                                'direction': direction,
                                'status': MessageStatus.DELIVERED,
                                'created_at': django_timezone.now(),
                                'metadata': {
                                    'api_data': message_data,
                                    'synced_from': 'background_sync_simple',
                                    'sync_time': django_timezone.now().isoformat()
                                }
                            }
                        )
                        
                        if created:
                            messages_created += 1
                    except Exception as e:
                        logger.error(f"Failed to process message {message_data.get('id')}: {e}")
                        continue
                
                stats['messages_synced'] += messages_created
                logger.info(f"‚úÖ Chat {chat_id}: {len(attendees)} attendees, {messages_created} messages")
                
            except Exception as e:
                logger.error(f"Failed to process chat {chat_data.get('id', 'unknown')}: {e}")
                stats['errors'].append(f"Chat {chat_data.get('id', 'unknown')}: {str(e)}")
                continue
        
        logger.info(f"‚úÖ Comprehensive sync complete: {stats}")
        return stats
        
    except Exception as e:
        logger.error(f"‚ùå Simplified comprehensive sync failed: {e}")
        stats['errors'].append(str(e))
        return stats


def _sync_conversations_paginated_sync(
    sync_job: SyncJob,
    channel: Channel,
    options: Dict[str, Any],
    db_connection
) -> List[Dict[str, Any]]:
    """
    Sync conversations with pagination and progress updates
    ASGI-compatible sync version with proper database context
    """
    logger.info(f"üì± Starting paginated conversation sync for {channel.name}")
    
    batch_size = options['conversations_per_batch']
    all_conversations = []
    batch_number = 0
    
    # Get UniPile client
    client = unipile_service.get_client()
    
    # Map channel type to UniPile account type
    account_type_map = {
        'whatsapp': 'WHATSAPP',
        'linkedin': 'LINKEDIN',
        'gmail': 'GOOGLE', 
        'outlook': 'OUTLOOK'
    }
    account_type = account_type_map.get(channel.channel_type, channel.channel_type.upper())
    
    cursor = sync_job.pagination_state.get('conversations_cursor') if sync_job.pagination_state else None
    
    try:
        while True:
            batch_number += 1
            logger.info(f"üì± Processing conversation batch {batch_number}")
            
            # Create progress entry for this batch
            progress_entry = SyncJobProgress.objects.create(
                sync_job=sync_job,
                phase_name='fetching_conversations',
                step_name=f'batch_{batch_number}',
                items_total=batch_size,
                started_at=django_timezone.now()
            )
            
            try:
                # Get real conversations from UniPile API
                client = unipile_service.get_client()
                
                # Map channel type to UniPile account type
                account_type_map = {
                    'whatsapp': 'WHATSAPP',
                    'linkedin': 'LINKEDIN',
                    'gmail': 'GOOGLE',
                    'outlook': 'OUTLOOK'
                }
                account_type = account_type_map.get(channel.channel_type, channel.channel_type.upper())
                
                import asyncio
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                try:
                    response = loop.run_until_complete(client.messaging.get_chats_batch(
                        account_id=channel.unipile_account_id,
                        account_type=account_type,
                        cursor=cursor,
                        limit=batch_size
                    ))
                    conversations = response.get('items', [])
                finally:
                    loop.close()
                
                if not conversations:
                    logger.info("üì± No more conversations to sync")
                    break
                
                # Process this batch of conversations
                batch_processed = []
                batch_errors = []
                start_time = datetime.now(timezone.utc)
                
                for i, conv_data in enumerate(conversations):
                    conv_start_time = datetime.now(timezone.utc)
                    try:
                        chat_id = conv_data.get('id')
                        conv_name = conv_data.get('name', 'Unnamed Conversation')
                        
                        if chat_id:
                            # Get or create conversation in database
                            conversation, created = Conversation.objects.get_or_create(
                                channel=channel,
                                external_thread_id=chat_id,
                                defaults={
                                    'subject': conv_name,
                                    'status': 'active',
                                    'sync_status': 'pending',
                                    'conversation_type': 'direct',  # Will update based on attendee count
                                    'metadata': conv_data
                                }
                            )
                            
                            # Process attendees if available in conversation data
                            attendee_count = 0
                            attendee_detector = WhatsAppAttendeeDetector(channel=channel)
                            
                            if 'attendees' in conv_data:
                                for attendee_data in conv_data.get('attendees', []):
                                    try:
                                        # Create or update attendee and link to conversation
                                        attendee = attendee_detector.create_or_update_attendee(
                                            attendee_data,
                                            conversation=conversation,
                                            channel=channel
                                        )
                                        if attendee:
                                            attendee_count += 1
                                    except Exception as attendee_error:
                                        logger.warning(f"Failed to process attendee for conversation {chat_id}: {attendee_error}")
                            
                            # Update conversation type based on attendee count
                            if attendee_count > 2:
                                conversation.conversation_type = 'group'
                            elif attendee_count == 2:
                                conversation.conversation_type = 'direct'
                            
                            # Update participant count
                            conversation.participant_count = attendee_count
                            conversation.save(update_fields=['conversation_type', 'participant_count'])
                            
                            # Calculate processing time
                            conv_processing_time = int((datetime.now(timezone.utc) - conv_start_time).total_seconds() * 1000)
                            
                            batch_processed.append({
                                'conversation_id': str(conversation.id),
                                'external_id': chat_id,
                                'name': conv_name,
                                'created': created,
                                'processing_time_ms': conv_processing_time,
                                'attendee_count': attendee_count
                            })
                            
                            # Update progress every 5 conversations
                            if (i + 1) % 5 == 0:
                                progress_current = len(all_conversations) + len(batch_processed)
                                sync_job.update_progress(
                                    conversations_processed=progress_current,
                                    current_phase='processing_conversations',
                                    current_step=f'batch_{batch_number}_item_{i+1}',
                                    current_conversation_name=conv_name,
                                    batch_progress_percent=int((i + 1) / len(conversations) * 100),
                                    avg_processing_time_ms=conv_processing_time
                                )
                            
                    except Exception as conv_error:
                        error_msg = str(conv_error)
                        batch_errors.append({
                            'conversation_id': conv_data.get('id', 'unknown'),
                            'conversation_name': conv_data.get('name', 'Unnamed'),
                            'error': error_msg
                        })
                        logger.error(f"Failed to process conversation {conv_data.get('id', 'unknown')}: {conv_error}")
                        continue
                
                all_conversations.extend(batch_processed)
                
                # Calculate batch performance metrics
                batch_processing_time = int((datetime.now(timezone.utc) - start_time).total_seconds() * 1000)
                avg_conversation_time = batch_processing_time / len(batch_processed) if batch_processed else 0
                error_rate = len(batch_errors) / len(conversations) * 100 if conversations else 0
                
                # Update progress entry
                progress_entry.items_processed = len(batch_processed)
                progress_entry.processing_time_ms = batch_processing_time
                progress_entry.step_status = 'completed' if not batch_errors else 'failed'
                progress_entry.completed_at = django_timezone.now()
                progress_entry.metadata = {
                    'error_count': len(batch_errors),
                    'error_rate_percent': error_rate,
                    'avg_processing_time_ms': int(avg_conversation_time),
                    'recent_errors': batch_errors[-3:] if batch_errors else []
                }
                progress_entry.save()
                
                # Update overall sync job progress
                sync_job.update_progress(
                    conversations_processed=len(all_conversations),
                    current_phase='fetching_conversations',
                    current_step=f'batch_{batch_number}_completed',
                    batch_number=batch_number,
                    conversations_in_batch=len(batch_processed),
                    batch_errors_count=len(batch_errors),
                    batch_error_rate_percent=error_rate,
                    batch_processing_time_ms=batch_processing_time,
                    avg_conversation_processing_ms=int(avg_conversation_time)
                )
                
                logger.info(f"üìä Batch {batch_number} completed: {len(batch_processed)} conversations processed, {len(batch_errors)} errors")
                
                # Check if we should continue (for demo purposes, limit to 2 batches)
                if batch_number >= 2:
                    logger.info("üì± Demo sync completed - limiting to 2 batches")
                    break
                
            except Exception as batch_error:
                logger.error(f"Conversation batch {batch_number} failed: {batch_error}")
                progress_entry.step_status = 'failed'
                progress_entry.metadata = {'error': str(batch_error)}
                progress_entry.completed_at = django_timezone.now()
                progress_entry.save()
                break
        
        logger.info(f"‚úÖ Conversation sync completed: {len(all_conversations)} conversations processed")
        return all_conversations
        
    except Exception as e:
        logger.error(f"‚ùå Conversation sync failed: {e}")
        raise


def _sync_messages_paginated_sync(
    sync_job: SyncJob,
    channel: Channel, 
    conversations: List[Dict[str, Any]],
    options: Dict[str, Any],
    db_connection
) -> int:
    """
    Sync messages for all conversations with pagination
    ASGI-compatible sync version
    """
    logger.info(f"üì® Starting paginated message sync for {len(conversations)} conversations")
    
    batch_size = options['messages_per_batch']
    total_messages_synced = 0
    
    for i, conv_data in enumerate(conversations):
        external_id = conv_data.get('external_id')
        if not external_id:
            continue
        
        logger.info(f"üì® Syncing messages for conversation {i+1}/{len(conversations)}: {external_id[:8]}")
        
        # Create progress entry for this conversation's messages
        progress_entry = SyncJobProgress.objects.create(
            sync_job=sync_job,
            phase_name='processing_messages',
            step_name=f'conversation_{external_id[:8]}',
            items_total=0,  # Will update as we discover message count
            started_at=django_timezone.now()
        )
        
        try:
            # Get conversation from database
            try:
                conversation = Conversation.objects.get(
                    channel=channel,
                    external_thread_id=external_id
                )
            except Conversation.DoesNotExist:
                logger.error(f"Conversation not found for external_id: {external_id}")
                continue
            
            conv_messages_synced = 0
            
            # Simulate message processing (replace with actual UniPile API call)
            # This is a placeholder implementation
            for batch_num in range(2):  # Simulate 2 batches of messages per conversation
                messages = []
                for msg_i in range(min(batch_size, 5)):  # Simulate small batch for demo
                    messages.append({
                        'id': f'msg_{external_id}_{batch_num}_{msg_i}',
                        'content': f'Demo message {msg_i} from conversation {external_id}',
                        'sender': 'demo_sender',
                        'timestamp': django_timezone.now().isoformat(),
                        'type': 'text'
                    })
                
                if not messages:
                    break
                
                # Process messages
                batch_processed = 0
                for message_data in messages:
                    try:
                        # Create message in database (placeholder)
                        from .models import Message
                        message, created = Message.objects.get_or_create(
                            conversation=conversation,
                            external_message_id=message_data['id'],
                            defaults={
                                'content': message_data['content'],
                                'sender_name': message_data['sender'],
                                'message_type': 'text',
                                'timestamp': django_timezone.now(),
                                'metadata': message_data
                            }
                        )
                        
                        if created:
                            batch_processed += 1
                        
                    except Exception as msg_error:
                        logger.error(f"Failed to process message {message_data.get('id', 'unknown')}: {msg_error}")
                        continue
                
                conv_messages_synced += batch_processed
                total_messages_synced += batch_processed
                
                logger.info(f"üì® Processed batch {batch_num + 1} for conversation {external_id[:8]}: {batch_processed} messages")
            
            # Update progress entry
            progress_entry.items_processed = conv_messages_synced
            progress_entry.items_total = conv_messages_synced
            progress_entry.step_status = 'completed'
            progress_entry.completed_at = django_timezone.now()
            progress_entry.save()
            
            # Update overall progress
            sync_job.update_progress(
                messages_processed=total_messages_synced,
                current_step=f'conversation_{i+1}_of_{len(conversations)}_completed'
            )
            
            logger.info(f"üì® Conversation {external_id[:8]}: {conv_messages_synced} messages synced")
            
        except Exception as conv_error:
            logger.error(f"Message sync failed for conversation {external_id}: {conv_error}")
            progress_entry.step_status = 'failed'
            progress_entry.metadata = {'error': str(conv_error)}
            progress_entry.completed_at = django_timezone.now()
            progress_entry.save()
            continue
    
    logger.info(f"‚úÖ Message sync completed: {total_messages_synced} messages processed")
    return total_messages_synced


# =========================================================================
# CHAT-SPECIFIC SYNC TASK
# =========================================================================

@shared_task(bind=True, max_retries=3)
def sync_chat_specific_background(
    self,
    channel_id: str,
    chat_external_id: str,
    user_id: str,
    sync_options: Optional[Dict[str, Any]] = None,
    tenant_schema: Optional[str] = None
):
    """
    Background sync for a specific chat conversation
    Useful for targeted sync operations
    """
    try:
        options = {**SYNC_CONFIG, **(sync_options or {})}
        
        logger.info(f"üéØ Starting chat-specific background sync for {chat_external_id}")
        
        # ASGI-compatible event loop setup
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            if tenant_schema:
                with schema_context(tenant_schema):
                    result = loop.run_until_complete(
                        _execute_chat_specific_sync(
                            self, channel_id, chat_external_id, user_id, options
                        )
                    )
            else:
                result = loop.run_until_complete(
                    _execute_chat_specific_sync(
                        self, channel_id, chat_external_id, user_id, options
                    )
                )
            
            return result
            
        finally:
            loop.close()
            
    except Exception as e:
        logger.error(f"‚ùå Chat-specific sync failed for {chat_external_id}: {e}")
        
        if self.request.retries < self.max_retries:
            retry_delay = options.get('retry_delay_base', 60) * (2 ** self.request.retries)
            raise self.retry(countdown=retry_delay)
        
        return {
            'success': False,
            'error': str(e),
            'chat_id': chat_external_id,
            'task_id': self.request.id
        }


async def _execute_chat_specific_sync(
    task,
    channel_id: str,
    chat_external_id: str,
    user_id: str,
    options: Dict[str, Any]
) -> Dict[str, Any]:
    """Execute chat-specific sync"""
    
    channel = await Channel.objects.aget(id=channel_id)
    user = await User.objects.aget(id=user_id)
    
    # Create sync job
    sync_job = await SyncJob.objects.acreate(
        user=user,
        channel=channel,
        job_type=SyncJobType.CHAT_SPECIFIC,
        sync_options={**options, 'chat_external_id': chat_external_id},
        celery_task_id=task.request.id,
        status=SyncJobStatus.RUNNING,
        started_at=django_timezone.now()
    )
    
    try:
        client = unipile_service.get_client()
        
        # Get connection for account identifier
        connection = await UserChannelConnection.objects.filter(
            user=user,
            channel=channel
        ).afirst()
        
        # Initialize attendee detector with channel (it will get account identifier automatically)
        attendee_detector = WhatsAppAttendeeDetector(channel=channel)
        account_identifier = attendee_detector.account_identifier
        
        # Sync messages for this specific chat
        messages_synced = 0
        cursor = None
        batch_size = options['messages_per_batch']
        
        while True:
            response = await client.messaging.get_messages_batch(
                chat_id=chat_external_id,
                cursor=cursor,
                limit=batch_size
            )
            
            messages = response.get('items', [])
            if not messages:
                break
            
            # Process messages
            for message_data in messages:
                try:
                    # Get or create conversation
                    conversation, _ = await Conversation.objects.aget_or_create(
                        channel=channel,
                        external_thread_id=chat_external_id
                    )
                    
                    # Detect sender and create/update attendee
                    sender_info = message_data.get('sender') or message_data.get('from')
                    if sender_info:
                        sender_attendee = await sync_to_async(attendee_detector.create_or_update_attendee)(
                            sender_info,
                            conversation=conversation,
                            channel=channel
                        )
                    else:
                        sender_attendee = None
                    
                    # Determine message direction
                    direction_str = determine_message_direction(
                        message_data,
                        'whatsapp',
                        account_identifier
                    )
                    # Convert 'in'/'out' to model's expected 'inbound'/'outbound'
                    direction = 'inbound' if direction_str == 'in' else 'outbound'
                    
                    # Create or update message
                    message, created = await Message.objects.aupdate_or_create(
                        channel=channel,
                        external_message_id=message_data.get('id'),
                        defaults={
                            'conversation': conversation,
                            'sender': sender_attendee,
                            'content': message_data.get('text', ''),
                            'direction': direction,
                            'status': MessageStatus.DELIVERED,
                            'created_at': django_timezone.now(),
                            'metadata': {
                                'api_data': message_data,
                                'synced_from': 'chat_specific_sync',
                                'sync_time': django_timezone.now().isoformat()
                            }
                        }
                    )
                    
                    if created:
                        messages_synced += 1
                        
                except Exception as e:
                    logger.error(f"Failed to process message: {e}")
                    continue
            
            # Update progress
            await sync_job.aupdate_progress(
                messages_processed=messages_synced,
                current_step=f'batch_completed'
            )
            
            # Check for next page
            cursor = response.get('next_cursor')
            has_more = response.get('has_more', False)
            
            if not has_more or not cursor:
                break
        
        # Finalize
        await _finalize_sync_job(sync_job, [], messages_synced)
        
        return {
            'success': True,
            'sync_job_id': str(sync_job.id),
            'messages_synced': messages_synced,
            'chat_id': chat_external_id,
            'task_id': task.request.id
        }
        
    except Exception as e:
        await _mark_sync_job_failed_async(sync_job, str(e))
        raise